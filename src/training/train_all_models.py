import os
import numpy as np
import pandas as pd
import joblib
import mlflow
import time

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from xgboost import XGBRegressor

# ===============================
# CONFIG
# ===============================
DATA_PATH = "/opt/airflow/data/processed/clean.csv"
MODEL_DIR = "/opt/airflow/models"
TARGET_COL = "CO(GT)"
FEATURE_COLS = [
    "PT08.S1(CO)", "NMHC(GT)", "C6H6(GT)", "PT08.S2(NMHC)",
    "NOx(GT)", "PT08.S3(NOx)", "NO2(GT)", "PT08.S4(NO2)",
    "PT08.S5(O3)", "T", "RH", "AH",
]

os.makedirs(MODEL_DIR, exist_ok=True)

# ===============================
# MLFLOW SETUP (C·∫•u h√¨nh ch·ªëng l·ªói 403)
# ===============================
# L·∫•y URI t·ª´ bi·∫øn m√¥i tr∆∞·ªùng, m·∫∑c ƒë·ªãnh l√† service name trong docker-compose
tracking_uri = os.getenv("MLFLOW_TRACKING_URI", "http://mlflow:5000")
mlflow.set_tracking_uri(tracking_uri)

experiment_name = "AIR_QUALITY_MLOPS"

# H√†m b·ªï tr·ª£ ƒë·ªÉ set experiment an to√†n
def setup_mlflow(name):
    try:
        # Ki·ªÉm tra xem experiment ƒë√£ t·ªìn t·∫°i ch∆∞a
        exp = mlflow.get_experiment_by_name(name)
        if exp is None:
            print(f"Creating new experiment: {name}")
            mlflow.create_experiment(name)
        mlflow.set_experiment(name)
    except Exception as e:
        print(f"‚ö†Ô∏è Warning: Could not connect to MLflow at {tracking_uri}")
        print(f"Error details: {e}")
        # N·∫øu l·ªói 403 ti·∫øp t·ª•c, code v·∫´n ch·∫°y nh∆∞ng kh√¥ng log v√†o MLflow
        return False
    return True

# Th·ª±c hi·ªán setup
is_mlflow_ready = setup_mlflow(experiment_name)

# ===============================
# LOAD & SPLIT DATA
# ===============================
print("Loading data...")
df = pd.read_csv(DATA_PATH, parse_dates=["datetime"])
X = df[FEATURE_COLS]
y = df[TARGET_COL]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ===============================
# TRAINING
# ===============================
print("üöÄ Training XGBoost model...")

# Kh·ªüi t·∫°o run (ch·ªâ khi MLflow s·∫µn s√†ng)
run = mlflow.start_run(run_name="XGBoost") if is_mlflow_ready else None

try:
    model = XGBRegressor(
        n_estimators=100,
        learning_rate=0.1,
        max_depth=5,
        objective="reg:squarederror",
        random_state=42
    )

    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    
    rmse = np.sqrt(mean_squared_error(y_test, preds))
    mae = mean_absolute_error(y_test, preds)
    r2 = r2_score(y_test, preds)

    if is_mlflow_ready:
        mlflow.log_params({
            "model": "XGBoost",
            "n_estimators": 100,
            "max_depth": 5
        })
        mlflow.log_metrics({"rmse": rmse, "mae": mae, "r2": r2})
        mlflow.xgboost.log_model(model, "model")

    print(f"‚úÖ Metrics: RMSE={rmse:.4f}, MAE={mae:.4f}, R2={r2:.4f}")

finally:
    if run:
        mlflow.end_run()

# ===============================
# SAVE MODEL LOCALLY
# ===============================
# ===============================
# SAVE MODEL TO ROOT (D√†nh cho FastAPI)
# ===============================
# ƒê∆∞·ªùng d·∫´n file model cu·ªëi c√πng
FINAL_MODEL_PATH = os.path.join(MODEL_DIR, "best_model.pkl")
FLAG_FILE_PATH = os.path.join(MODEL_DIR, "MODEL_READY")

# L∆∞u model th·ª±c t·∫ø
joblib.dump(model, FINAL_MODEL_PATH)

# L∆∞u timestamp v√†o file READY ƒë·ªÉ FastAPI nh·∫≠n di·ªán c√≥ model m·ªõi
with open(FLAG_FILE_PATH, "w") as f:
    f.write(str(time.time()))

print(f"üíæ Model saved to: {FINAL_MODEL_PATH}")
print("üéâ Pipeline finished!")

print("üéâ Training completed!")